# Optimization

The Optimization problems of finding the most appropriate ("best") solutions out of all feasible solutions are every where, in operations research, supply chain, manufacturing, design, games, etc. Often this involves finding the maximum or minimum value of some function: the minimum time to make a certain journey, the minimum cost for doing a task, the maximum power that can be generated by a device, and so on. Though mostly calculus techniques are applied to solve the problem. 

These are also among the most difficult problems in computer science and belong to a complexity class for decision problems called NP-Complete Problems. These problems have two properties, we cah check a solution quickly(in polynomial time) and if we can solve one NP-complete quickly, we can solve them all. 

A well designed optimization model provide unique insights into the situations, compare different scenarios, aid in what-if analysis, revealing areas of possible improvements and so on. Every optimization problem has three components: an objective function, decision variables, and constraints.

Mathematically, optimization problem operate on a vector of variables $x=(x_1, \dots, x_n)$ that are to be optimized to find an optimal solution vector $x*$ such that the objective function $f_0: \mathbb R^n \rightarrow \mathbb R$ is maximized or minimized, satisfying certain bounds and constraints $f_i(x) : \mathbb R^n \rightarrow \mathbb R, i=1, \dots, m$ and takes the form:

$$
\begin{array}{ll}
\operatorname{minimize} & f_0(x) \\
\text { subject to } & f_i(x) \leq b_i, \quad i=1, \dots, m
\end{array}
$$

Many class of optimization problems are characterized by these objective and constraint functions
- Based on type of variables we are optimizing
  - Continuous: Easier to solve.
  - Discrete
- Based on Constraints on the variables
  - Unconstrained: Objective functions and the optimization variables are not constrained or bound.
  - Constrained Optimization:
    - Sparsed: if each constraint function depends on only a small number of variables 
- Based on Linearity of Objective and constraint functions
  - Linear Program: if the objective and constraint functions $f_0 , . . . , f_m$ are linear (i.e $f_i (\alpha x + \beta y) = \alpha f_i (x) + \beta f_i (y))$
  - Non-Linear Program: if objective or constraints are non-linear
- Based on Convexity of the objective or constraints functions (more general than linearity)
  - Convex Optimization :the objective and constraint functions are convex, it must satisfy
    $$f_i (\alpha x + \beta y) \leq \alpha f_i (x) + \beta f_i (y)), \forall x, y \in \mathbb R^n \text{ and } \forall \alpha, \beta \in \mathbb R : \alpha + \beta = 1, \alpha \geq 0, \beta \geq 0$$
  - Non-Convex Optimization
- Based on the number of objective functions
  - None
  - One
  - Many
- Based on Functional Smoothness
  - Differentiable
  - Non-Differentiable
- Deterministic vs Stochastic
  - Deterministic algorithms have specific rules for moving from one solution to another. Data for problem is known accurately
  - Stochastic Algorithms have probabilistic transition rules. Data cannot be known precisely for various reasons (measurement error, future uncertainty).

 The Solution for many of these types of problem mostly depends on the type of optimization problem and their characteristics.
- Linear Programming (LP) vs Quadratic Programming (QP) problems: objective function being linear or quadratic function of the decision variable
- Local Search (LS)
- Integer Programming (IP)
- Mixed Integer Programming (MIP)
- Evolutionary Algorithms


## Applications
- Portfolio Optimization: optimal allocation of capital investment in a set of n assets, maximizing overall return or minimizing the overall risk(variance), under limited non-negative budget and minimum acceptable expectable return on the whole portfolio.
- Design(Mechanical, Civil, Electronic, ...): finding optimal dimensions for the component under variety of engineering requirements 
- Machine Learning: Find optimal model parameters that optimizes the loss functions (misfit or prediction error) constrained by prior information or limits on the parameters.
- Automatic Control
- Supply Chain Problems
  - Routing
  - Scheduling





## Julia Ecosystem for Optimization

JuliaOpt organisation is Obsolete

- [Jump](https://github.com/jump-dev/JuMP.jl) : An algebraic modeling language for linear, quadratic, and nonlinear constrained optimization problems.
- [Convex.jl](https://github.com/JuliaOpt/Convex.jl): An algebraic modeling language for disciplined convex programming.
- [JuliaSmoothOptimizers](https://github.com/JuliaSmoothOptimizers) provides a collection of tools primarily designed for developing solvers for smooth nonlinear optimization.
- [JuliaNLSolvers](https://github.com/JuliaNLSolvers) offers implementations in Julia of standard standard optimization algorithms for unconstrained or box-constrained problems such as BFGS, Nelder-Mead, conjugate gradient, etc.

Others
- [JuliaOptPackages](http://www.juliaopt.org/packages/)


## References
- [Convex Optimization by Stephan Boyd, Lieven Vandenberghe]
- [Julia for Operation Research](https://juliabook.chkwon.net/book) by Changhyun Kwon
- https://github.com/JuliaOpt/juliaopt-notebooks
